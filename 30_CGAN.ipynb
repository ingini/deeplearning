{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빅데이터 활용 AI 설계\n",
    "# CGAN : Conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets.mnist import load_data\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train/255\n",
    "X_train = X_train[:,:,:,np.newaxis]\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriminator 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Reshape, Concatenate, Conv2D, \\\n",
    "        LeakyReLU, Flatten, Dropout, Dense, Conv2DTranspose\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\multicampus\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\multicampus\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\multicampus\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 28, 28, 2) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_label = Input((1,))\n",
    "x_label = Embedding(10, 50)(in_label)\n",
    "x_label = Dense(28*28)(x_label)\n",
    "x_label = Reshape((28,28,1))(x_label) # 0~9 의 레이블을 받아들여서 28*28 인 채널을 하나 생성함\n",
    "\n",
    "in_image = Input((28,28,1))\n",
    "\n",
    "x = Concatenate()([in_image, x_label]) # 흑백이미지는 채널이 1, 레이블 채널을 추가해서 채널이 2가 됨\n",
    "\n",
    "x # (?, 28, 28, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\multicampus\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\multicampus\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\multicampus\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\multicampus\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\multicampus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 50)        500         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 784)       39984       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 28, 28, 1)    0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 28, 28, 2)    0           input_2[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 128)  2432        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 14, 14, 128)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 128)    147584      leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 7, 7, 128)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6272)         0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 6272)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            6273        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 196,773\n",
      "Trainable params: 196,773\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Conv2D(128, (3,3), strides=(2,2), padding='same')(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = Conv2D(128, (3,3), strides=(2,2), padding='same')(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = Model([in_image, in_label], output)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['acc'])\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_2/concat:0' shape=(?, 7, 7, 129) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_label = Input((1,))\n",
    "x_label = Embedding(10, 50)(in_label)\n",
    "x_label = Dense(7*7)(x_label)\n",
    "x_label = Reshape((7,7,1))(x_label) # 0~9 의 레이블을 받아들여서 7*7 인 채널을 하나 생성함\n",
    "\n",
    "in_latent = Input((100,))\n",
    "x_latent = Dense(7*7*128)(in_latent)\n",
    "x_latent = LeakyReLU(alpha=0.2)(x_latent)\n",
    "x_latent = Reshape((7,7,128))(x_latent)\n",
    "\n",
    "x = Concatenate()([x_latent, x_label]) # (7,7,128) 생성 이미지층과 (7,7,1) 레이블 층을 결합\n",
    "\n",
    "x # (?, 7, 7, 129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "output = Conv2D(1, (7,7), activation='sigmoid', padding='same')(x)  # why tanh not sigmoid?\n",
    "\n",
    "generator = Model([in_latent, in_label], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 6272)         633472      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 50)        500         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 6272)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 49)        2499        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 7, 7, 128)    0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 7, 7, 1)      0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 7, 7, 129)    0           reshape_3[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 14, 14, 128)  264320      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 14, 14, 128)  0           conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 128)  262272      leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 28, 28, 128)  0           conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 28, 28, 1)    6273        leaky_re_lu_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,169,336\n",
      "Trainable params: 1,169,336\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 6272)         633472      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 50)        500         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 6272)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 49)        2499        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 7, 7, 128)    0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 7, 7, 1)      0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 7, 7, 129)    0           reshape_3[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 14, 14, 128)  264320      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 14, 14, 128)  0           conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 128)  262272      leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 28, 28, 128)  0           conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 28, 28, 1)    6273        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            196773      conv2d_3[0][0]                   \n",
      "                                                                 input_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,366,109\n",
      "Trainable params: 1,169,336\n",
      "Non-trainable params: 196,773\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "#adversarial = Model([in_latent, in_label], discriminator([generator([in_latent, in_label]), in_label])\n",
    "adversarial = Model([in_latent, in_label], discriminator([output, in_label]))\n",
    "adversarial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00001,  [0.563316, 0.9296875, 1.0270109, 0.0]\n",
      "Step: 00002,  [0.566252, 0.9296875, 0.98907614, 0.0]\n",
      "Step: 00003,  [0.57078326, 0.984375, 0.9372088, 0.0]\n",
      "Step: 00004,  [0.57538927, 0.9765625, 0.8843864, 0.0]\n",
      "Step: 00005,  [0.5832373, 0.9921875, 0.82183045, 0.0]\n",
      "Step: 00006,  [0.5837163, 1.0, 0.7821143, 0.0]\n",
      "Step: 00007,  [0.580681, 1.0, 0.7528669, 0.0]\n",
      "Step: 00008,  [0.5666158, 1.0, 0.73201615, 0.0]\n",
      "Step: 00009,  [0.5619673, 0.984375, 0.7160182, 0.0]\n",
      "Step: 00010,  [0.54742575, 0.9453125, 0.70954573, 0.015625]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cgan_images/fake_00010.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c7abde8b384c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_to_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cgan_images/fake_%05d.png'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2083\u001b[0m                 \u001b[1;31m# Open also for reading (\"+\"), because TIFF save_all\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2084\u001b[0m                 \u001b[1;31m# writer needs to go back and edit the written data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2085\u001b[1;33m                 \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w+b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2087\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cgan_images/fake_00010.png'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "batch_size = 64\n",
    "logs = [] # d_loss,d_acc,a_loss,a_acc\n",
    "\n",
    "for step in range(100):\n",
    "    indices = np.random.randint(0, len(X_train), size=batch_size)\n",
    "    real_images = X_train[indices]\n",
    "    real_labels = y_train[indices]\n",
    "    \n",
    "    gen_vectors = np.random.uniform(-1, 1, size=[batch_size,100])\n",
    "    gen_labels = np.random.randint(10, size=batch_size)\n",
    "    fake_images = generator.predict([gen_vectors, gen_labels])\n",
    "    \n",
    "    X = np.r_[real_images, fake_images] # [batch_size*2,28,28,1]\n",
    "    y_label = np.r_[real_labels, gen_labels] # (batch_size*2,)\n",
    "    y = np.r_[np.ones([batch_size,1]), np.zeros([batch_size,1])] # [batch_size*2,1]\n",
    "        # fake: 0, real: 1\n",
    "        \n",
    "    ###########\n",
    "    d_loss, d_acc = discriminator.train_on_batch([X,y_label], y)\n",
    "    \n",
    "    gen_vectors_2 = np.random.uniform(-1, 1, size=[batch_size,100])\n",
    "    gen_labels2 = np.random.randint(10, size=(batch_size,1))\n",
    "    ###########\n",
    "    a_loss, a_acc = adversarial.train_on_batch([gen_vectors_2, gen_labels2], np.ones([batch_size,1]))\n",
    "            # 타겟값을 모두 1로 놓는다\n",
    "    \n",
    "    logs.append([d_loss,d_acc,a_loss,a_acc])\n",
    "    print('Step: %05d, ' % (step+1), logs[-1])\n",
    "    \n",
    "    if (step+1)%10 == 0:\n",
    "        adversarial.save_weights('gan_mnist.h5')\n",
    "    \n",
    "        img = image.array_to_img(fake_images[0]*255., scale=False)\n",
    "        img.save('cgan_images/fake_%05d.png' % (step+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1982d3c9c08>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i[0] for i in logs][::10], 'b-', label='d_loss')\n",
    "plt.plot([i[2] for i in logs][::10], 'r-', label='a_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1982d476b08>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i[1] for i in logs][::10], 'b-', label='d_acc')\n",
    "plt.plot([i[3] for i in logs][::10], 'r-', label='a_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "하위 디렉터리 또는 파일 gan_images이(가) 이미 있습니다.\n"
     ]
    }
   ],
   "source": [
    "! mkdir gan_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "batch_size = 64\n",
    "logs= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[ 0.42797967, -0.17640734, -0.67923813, ...,  0.34510732,\n        -0.54497084,  0.27994231],\n       [-0.0833857 , -0.2255967 ,  0.96361608, ...,  0.55016991,\n        -0.71692912, -0.7806871 ],...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-1615ce6b091b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mgen_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mfake_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1380\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1381\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[1;34m'Expected to see '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' array(s), '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m                 \u001b[1;34m'but instead got the following list of '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             raise ValueError(\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[ 0.42797967, -0.17640734, -0.67923813, ...,  0.34510732,\n        -0.54497084,  0.27994231],\n       [-0.0833857 , -0.2255967 ,  0.96361608, ...,  0.55016991,\n        -0.71692912, -0.7806871 ],..."
     ]
    }
   ],
   "source": [
    "for step in range(1000):\n",
    "    indices = np.random.randint(0, len(X_train),size=batch_size)\n",
    "    real_image =X_train[indices]\n",
    "        \n",
    "    gen_vectors = np.random.uniform(-1,1,size=[batch_size,100])\n",
    "    fake_images = generator.predict(gen_vectors)\n",
    "    \n",
    "    X = np.r_[real_images,fake_images]\n",
    "    y = np.r_[np.ones([batch_size,1]), np.zeros([batch_size,1])]\n",
    "    \n",
    "    d_loss, d_acc = discriminator.train_on_batch(X,y)\n",
    "    \n",
    "    gen_vectors_2 = np.random.uniform(-1,1, size=[batch_size,100])\n",
    "    \n",
    "    a_loss, a_acc = adversarial.train_on_batch(gen_vectors_2,np.ones([batch_size,1]))\n",
    "    \n",
    "    logs.append([d_loss,d_acc,a_loss,a_acc])\n",
    "    print('Step: %05d, ' % (step+1), logs[-1])\n",
    "    \n",
    "    if (step+1)%10 == 0:\n",
    "        \n",
    "        img = image.array_to_img(fake_images[0]*255, scale= False)\n",
    "        img.save('gan_image/fake_'+str(step+1)+'.png')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
