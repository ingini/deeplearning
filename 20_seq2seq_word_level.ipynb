{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빅데이터 활용 AI 설계\n",
    "# Seq2seq word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines= pd.read_table('mar.txt', names=['eng', 'mar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>जा.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>पळ!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eng  mar\n",
       "0   Go.  जा.\n",
       "1  Run!  पळ!"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35832, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "lines.mar=lines.mar.apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines.mar=lines.mar.apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.mar=lines.mar.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "lines.mar = lines.mar.apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
    "lines.mar=lines.mar.apply(lambda x: x.strip())\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.mar=lines.mar.apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function maketrans:\n",
      "\n",
      "maketrans(x, y=None, z=None, /)\n",
      "    Return a translation table usable for str.translate().\n",
      "    \n",
      "    If there is only one argument, it must be a dictionary mapping Unicode\n",
      "    ordinals (integers) or characters to Unicode ordinals, strings or None.\n",
      "    Character keys will be then converted to ordinals.\n",
      "    If there are two arguments, they must be strings of equal length, and\n",
      "    in the resulting dictionary, each character in x will be mapped to the\n",
      "    character at the same position in y. If there is a third argument, it\n",
      "    must be a string, whose characters will be mapped to None in the result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(str.maketrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "lines.mar = lines.mar.apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go</td>\n",
       "      <td>START_ जा _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run</td>\n",
       "      <td>START_ पळ _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run</td>\n",
       "      <td>START_ धाव _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run</td>\n",
       "      <td>START_ पळा _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run</td>\n",
       "      <td>START_ धावा _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eng               mar\n",
       "0   go    START_ जा _END\n",
       "1  run    START_ पळ _END\n",
       "2  run   START_ धाव _END\n",
       "3  run   START_ पळा _END\n",
       "4  run  START_ धावा _END"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 사전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary of English\n",
    "eng_words=set()\n",
    "for eng in lines.eng:\n",
    "    for word in eng.split():\n",
    "        if word not in eng_words:\n",
    "            eng_words.add(word)\n",
    "\n",
    "# Vocabulary of Marathi \n",
    "mar_words=set() \n",
    "for mar in lines.mar:\n",
    "    for word in mar.split():\n",
    "        if word not in mar_words:\n",
    "            mar_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5471, 13009)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_words = sorted(list(eng_words))\n",
    "mar_words = sorted(list(mar_words))\n",
    "\n",
    "len(eng_words), len(mar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'abbreviation',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10', '100', '300', '3ds', 'START_', '_END', 'a', 'b', 'h₂o', 'ntt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mar_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 37)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_seq_max = max([len(sen.split()) for sen in lines.eng])\n",
    "mar_seq_max = max([len(sen.split()) for sen in lines.mar])\n",
    "\n",
    "eng_seq_max, mar_seq_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 사전 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_w2i = dict([(word, i+1) for i, word in enumerate(eng_words)]) # 1번 부터 매김 (0 은 뒷부분의 패팅)\n",
    "mar_w2i = dict([(word, i+1) for i, word in enumerate(mar_words)]) # 1번 부터 매김 (0 은 뒷부분의 패팅)\n",
    "\n",
    "eng_i2w = dict((i, word) for word, i in eng_w2i.items())\n",
    "mar_i2w = dict((i, word) for word, i in mar_w2i.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 섞기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19353</th>\n",
       "      <td>i make too many mistakes</td>\n",
       "      <td>START_ मी खूपच चुका करतो _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15429</th>\n",
       "      <td>where are my slippers</td>\n",
       "      <td>START_ माझे स्लिपर कुठे आहेत _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>tom is an actor</td>\n",
       "      <td>START_ टॉम एक अभिनेता आहे _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8241</th>\n",
       "      <td>dont do that here</td>\n",
       "      <td>START_ तसं इथे करू नकोस _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29989</th>\n",
       "      <td>what are you going to do tomorrow</td>\n",
       "      <td>START_ तुम्ही उद्या काय करणार आहात _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     eng  \\\n",
       "19353           i make too many mistakes   \n",
       "15429              where are my slippers   \n",
       "4553                     tom is an actor   \n",
       "8241                   dont do that here   \n",
       "29989  what are you going to do tomorrow   \n",
       "\n",
       "                                           mar  \n",
       "19353            START_ मी खूपच चुका करतो _END  \n",
       "15429        START_ माझे स्लिपर कुठे आहेत _END  \n",
       "4553            START_ टॉम एक अभिनेता आहे _END  \n",
       "8241              START_ तसं इथे करू नकोस _END  \n",
       "29989  START_ तुम्ही उद्या काय करणार आहात _END  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련/테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32248,), (32248,), (3584,), (3584,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = lines.eng, lines.mar # 35832\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배치 샘플 생성자\n",
    "- 학습데이터(X_train, y_train) 에서 128 개씩 데이터를 가져온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, eng_seq_max),dtype='float32') # (128,34)\n",
    "            decoder_input_data = np.zeros((batch_size, mar_seq_max),dtype='float32') # (128,37)\n",
    "            decoder_target_data = np.zeros((batch_size, mar_seq_max, len(mar_words)+1),dtype='float32')\n",
    "                # (128,37,13010), 패딩값 0 이 들어가기 때문에 len(mar_words)+1 이다.\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = eng_w2i[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1: # 끝에 '_END' 를 제외\n",
    "                        decoder_input_data[i, t] = mar_w2i[word] # decoder input seq\n",
    "                    if t>0: # 앞부분 'START_' 제외\n",
    "                        # decoder target sequence (one hot encoded)len(mar_words)+1\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, mar_w2i[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(None,))\n",
    "x1 =  Embedding(len(eng_words)+1, word_vector_dim, mask_zero=True)(encoder_input)\n",
    "    # mask_zero=True: padding 인 0 을 처리하지 않음\n",
    "encoder_outputs, state_h, state_c = LSTM(word_vector_dim, return_state=True)(x1)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(None,))\n",
    "x2 = Embedding(len(mar_words)+1, word_vector_dim, mask_zero=True)(decoder_input)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_outputs, _, _ = LSTM(word_vector_dim, return_sequences=True, return_state=True)(x2, initial_state=encoder_states)\n",
    "decoder_outputs = Dense(len(mar_words)+1, activation='softmax')(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_input, decoder_input], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "251/251 [==============================] - 3585s 14s/step - loss: 6.5099 - acc: 0.1770 - val_loss: 5.8541 - val_acc: 0.1803\n",
      "Epoch 2/5\n",
      "251/251 [==============================] - 3482s 14s/step - loss: 5.6193 - acc: 0.2070 - val_loss: 5.5083 - val_acc: 0.2213\n",
      "Epoch 3/5\n",
      "251/251 [==============================] - 3595s 14s/step - loss: 5.3280 - acc: 0.2318 - val_loss: 5.3015 - val_acc: 0.2418\n",
      "Epoch 4/5\n",
      "251/251 [==============================] - 3598s 14s/step - loss: 5.1232 - acc: 0.2531 - val_loss: 5.1332 - val_acc: 0.2609\n",
      "Epoch 5/5\n",
      "251/251 [==============================] - 3535s 14s/step - loss: 4.9340 - acc: 0.2745 - val_loss: 4.9700 - val_acc: 0.2800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x265805fd198>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = 128),\n",
    "                    steps_per_epoch = len(X_train)//128,\n",
    "                    epochs=5,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = 128),\n",
    "                    validation_steps = len(X_test)//128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('eng_mar_weights.h5')\n",
    "model.load_weights('eng_mar_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method load_weights in module keras.engine.network:\n",
      "\n",
      "load_weights(filepath, by_name=False, skip_mismatch=False, reshape=False) method of keras.engine.training.Model instance\n",
      "    Loads all layer weights from a HDF5 save file.\n",
      "    \n",
      "    If `by_name` is False (default) weights are loaded\n",
      "    based on the network's topology, meaning the architecture\n",
      "    should be the same as when the weights were saved.\n",
      "    Note that layers that don't have weights are not taken\n",
      "    into account in the topological ordering, so adding or\n",
      "    removing layers is fine as long as they don't have weights.\n",
      "    \n",
      "    If `by_name` is True, weights are loaded into layers\n",
      "    only if they share the same name. This is useful\n",
      "    for fine-tuning or transfer-learning models where\n",
      "    some of the layers have changed.\n",
      "    \n",
      "    # Arguments\n",
      "        filepath: String, path to the weights file to load.\n",
      "        by_name: Boolean, whether to load weights by name\n",
      "            or by topological order.\n",
      "        skip_mismatch: Boolean, whether to skip loading of layers\n",
      "            where there is a mismatch in the number of weights,\n",
      "            or a mismatch in the shape of the weight\n",
      "            (only valid when `by_name`=True).\n",
      "        reshape: Reshape weights to fit the layer when the correct number\n",
      "            of weight arrays is present but their shape does not match.\n",
      "    \n",
      "    \n",
      "    # Raises\n",
      "        ImportError: If h5py is not available.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.load_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'abbreviation',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '100',\n",
       " '300',\n",
       " '3ds',\n",
       " 'START_',\n",
       " '_END',\n",
       " 'a',\n",
       " 'b',\n",
       " 'h₂o',\n",
       " 'ntt',\n",
       " 'tatoebaorg',\n",
       " 'uk',\n",
       " 'अ',\n",
       " 'अँकरेजमार्गे',\n",
       " 'अँजिलीस',\n",
       " 'अँड',\n",
       " 'अँडी',\n",
       " 'अँडीजमधल्या',\n",
       " 'अँब्युलन्स',\n",
       " 'अंक']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mar_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'i am tom'\n",
    "l = [eng_w2i[w] for w in s.split()]\n",
    "l = l + [0]*(34-len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 34)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([l])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.zeros([1,37])\n",
    "b[0,0] = mar_w2i['START_']\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मी'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = mar_i2w[np.argmax(model.predict([a,b])[0,0])]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.000e+00, 9.187e+03, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.zeros([1,37])\n",
    "b[0,0] = mar_w2i['START_']\n",
    "b[0,1] = mar_w2i['मी']\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मी'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = mar_i2w[np.argmax(model.predict([a,b])[0,0])]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मी'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.zeros([1,37])\n",
    "b[0,0] = mar_w2i['START_']\n",
    "b[0,1] = mar_w2i['मी']\n",
    "b[0,2] = mar_w2i['मी']\n",
    "\n",
    "r = mar_i2w[np.argmax(model.predict([a,b])[0,0])]\n",
    "r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
